{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyMD/Dx+VDH3UWwxayT1xq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iiBastzaZFn2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.discriminate = nn.Sequential(\n","        nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(256, 1, 4, 1, 0, bias=False),\n","        nn.Sigmoid()\n","    )\n","    \n","  def forward(self, input):\n","    return self.discriminate(input)\n","\n","\n","class Generator(nn.Module):\n","  def __init__(self, in_channel):\n","    super(Generator, self).__init__()\n","    self.generate = nn.Sequential(\n","        nn.ConvTranspose2d(in_channel, 256, 4, 1, 0, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(True),\n","        nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(True),\n","        nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(True),\n","        nn.ConvTranspose2d(64, 1, 4, 2, 3, bias=False),\n","        nn.Tanh()\n","    )\n","\n","    self.gen1 = nn.Sequential(\n","        nn.ConvTranspose2d(in_channel, 256, 4, 1, 0, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(True),\n","    )\n","    self.gen2 = nn.Sequential(\n","        nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(True),\n","    )\n","    self.gen3 = nn.Sequential(\n","        nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(True),\n","    )\n","    self.gen4 = nn.Sequential(\n","        nn.ConvTranspose2d(64, 1, 4, 2, 3, bias=False),\n","        nn.Tanh()\n","    )\n","\n","  \n","  def forward(self, input):\n","    #return self.generate(input)\n","    x = self.gen1(input)\n","    print(x.shape)\n","    x = self.gen2(x)\n","    print(x.shape)\n","    x = self.gen3(x)\n","    print(x.shape)\n","    x = self.gen4(x)\n","\n","    sdfdsfsdf\n","    return x\n"]},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import torch.utils.data as data\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torchvision.datasets import FashionMNIST\n","\n","class Network():\n","  def __init__(self, latent_dims=64, num_epochs=50, batch_size=64, learning_rate=1.0e-3, gpu=True):\n","    self.latent_dims = latent_dims\n","    self.num_epochs = num_epochs\n","    self.batch_size = batch_size\n","    self.in_channel = 64\n","    self.learning_rate = learning_rate\n","    self.gpu = gpu\n","    self.dur_time = 0\n","\n","    self._init_dataset()\n","    self._init_model()\n","\n","  def _init_dataset(self):\n","\n","    train_data2 = FashionMNIST(root='./dataset', download=True, train=True, transform=transforms.ToTensor())\n","    test_data2 = FashionMNIST(root='./dataset', download=True, train=False, transform=transforms.ToTensor())\n","\n","    self.train_queue2 = data.DataLoader(train_data2, batch_size=self.batch_size, shuffle=True, drop_last=True)\n","    self.test_queue2 = data.DataLoader(test_data2, batch_size=self.batch_size, shuffle=True, drop_last=True)\n","\n","  def _init_model(self):\n","    self.device = torch.device('cuda' if (torch.cuda.is_available() & self.gpu) else 'cpu')\n","\n","    Gen = Generator(self.in_channel).to(self.device)\n","    Dis = Discriminator().to(self.device)\n","    self.Gen = Gen.to(self.device)\n","    self.Dis = Dis.to(self.device)\n","\n","    self.criterion = nn.BCELoss()\n","\n","    #self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n","    self.G_optimizer = optim.Adam(self.Gen.parameters(), lr=self.learning_rate)    # optimizer\n","    self.D_optimizer = optim.Adam(self.Dis.parameters(), lr=self.learning_rate)\n","\n","  def show_images(self, images, num_images=16):\n","    #sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n","    sqrtn = int(np.ceil(np.sqrt(num_images)))\n","\n","    for index, image in enumerate(images):\n","      if index < num_images:\n","        plt.subplot(sqrtn, sqrtn, index+1)\n","        plt.imshow(image.reshape(28, 28))\n","        plt.axis('off')\n","\n","\n","  def calc_time(self, seconds):\n","    m, s = divmod(seconds, 60)\n","    h, m = divmod(m, 60)\n","    t, h = divmod(h, 24)\n","    return {'day':t, 'hour':h, 'minute':m, 'second':int(s)}\n","    \n","\n","  def train_fashion(self):\n","    G_loss_list = []\n","    D_loss_list = []\n","    run_start = time.time()\n","\n","    self.Gen.train()\n","    self.Dis.train()\n","    for epoch in range(self.num_epochs):\n","      G_loss_sum = 0\n","      D_loss_sum = 0\n","\n","      show_inputs = None\n","      show_outputs = None\n","      for step, (inputs, _) in enumerate(self.train_queue2):\n","        # Train Disciminator For Real Image\n","        self.D_optimizer.zero_grad()\n","\n","        inputs_real = inputs.to(self.device) # 64,1,28,28\n","        real_label = torch.ones(self.batch_size,).to(self.device) # 64個1，代表真實的圖片\n","        inputs_real_predict = self.Dis(inputs_real)\n","\n","        #print(inputs_real_predict.shape, real_label.shape)\n","        D_real_loss = self.criterion(inputs_real_predict.view(-1), real_label) # view make [64,1,1,1] -> [64] and cal loss\n","        D_real_loss.backward()\n","\n","        # Train Disciminator For Fake Image\n","        noise = torch.tensor(torch.randn(self.batch_size, self.in_channel, 1, 1, device=self.device)) # torch.Size([64, 100, 1, 1])\n","        fake_label = torch.zeros(self.batch_size,).to(self.device)   # 64個0，代表假的圖片\n","        fake_out = self.Gen(noise)                   # 64,1,28,28\n","        fake_predict = self.Dis(fake_out)               # 64,1,1,1\n","        D_fake_loss = self.criterion(fake_predict.view(-1), fake_label) # view make [64,1,1,1] -> [64] and cal loss\n","        D_fake_loss.backward()\n","\n","        D_total_loss = D_real_loss + D_fake_loss\n","        D_loss_list.append(D_total_loss.item())\n","        D_loss_sum += D_total_loss\n","        self.D_optimizer.step()\n","\n","        self.G_optimizer.zero_grad()\n","\n","        # 訓練生成真實圖片\n","        noise = torch.tensor(torch.randn(self.batch_size, self.in_channel, 1, 1, device=self.device)) # torch.Size([64, 100, 1, 1])\n","        target_label = torch.ones(self.batch_size,).to(self.device) # 64個1，代表希望產生的真實圖片\n","        fake_out2 = self.Gen(noise)      # 生成假圖片\n","        fake_predict2 = self.Dis(fake_out2)  # 獲得Discriminator的判斷\n","\n","        G_loss = self.criterion(fake_predict2.view(-1), target_label)\n","        G_loss_list.append(G_loss.item())\n","        G_loss_sum += G_loss\n","        G_loss.backward()\n","        self.G_optimizer.step()\n","\n","        show_outputs = fake_out2.detach().cpu().numpy()\n","      \n","      trainG_avg_loss = G_loss_sum/step\n","      trainD_avg_loss = D_loss_sum/step\n","      print('Epoch [{}]/[{}], D Loss:{}, G Loss:{}'.format(epoch, self.num_epochs, trainD_avg_loss, trainG_avg_loss))\n","      print('cost time: {}'.format(self.calc_time(self.dur_time + time.time() - run_start)))\n","\n","      #if epoch == self.num_epochs-1:\n","        #self.show_images(show_inputs)\n","        #plt.savefig('inputs_fashion_'+str(self.latent_dims)+'.png')\n","        #plt.show()\n","      self.show_images(show_outputs)\n","      plt.savefig('outputs_fashion_'+str(self.latent_dims)+'.png')\n","      plt.show()\n","\n","    plt.subplot(211)\n","    plt.plot(G_loss_list)\n","    plt.subplot(212)\n","    plt.plot(D_loss_list)\n","\n","    torch.save(self.Gen, './DCGAN_Generator_fashion.pth')\n","    torch.save(self.Dis, './DCGAN_Discriminator_fashion.pth')\n"],"metadata":{"id":"ezf2mVMFklyS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training latent dimension = 64 \n","if __name__ == '__main__':\n","    train_network = Network()\n","    train_network.train_fashion()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"LFa217MVGrCI","executionInfo":{"status":"error","timestamp":1650275378243,"user_tz":-480,"elapsed":501,"user":{"displayName":"王一鈞","userId":"09708156756334996196"}},"outputId":"9dca98c2-61a6-45d0-f4fb-522e1287320d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 256, 4, 4])\n","torch.Size([64, 128, 8, 8])\n","torch.Size([64, 64, 16, 16])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-58e98a75e818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fashion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-e38bb5fc903d>\u001b[0m in \u001b[0;36mtrain_fashion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([64, 100, 1, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mfake_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 64個0，代表假的圖片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mfake_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# 64,1,28,28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mfake_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_out\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# 64,1,1,1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mD_fake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# view make [64,1,1,1] -> [64] and cal loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-ad1782bce9d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0msdfdsfsdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sdfdsfsdf' is not defined"]}]}]}